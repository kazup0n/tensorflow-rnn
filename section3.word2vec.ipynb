{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize_aozora import Task,DownloadAozora,TokenCounter,SortByFreq,noun_filter,DataSet,Process\n",
    "from janome.tokenizer import Tokenizer\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "\n",
    "class RemoveMetaData(Process):\n",
    "    \n",
    "    def apply(self, lines):\n",
    "        \n",
    "        def remove(line):\n",
    "            s = line\n",
    "            s = s.replace('|','')\n",
    "            s = re.sub(r'《.+?》','',s) # ルビをとる\n",
    "            s = re.sub(r'［＃.+?］','',s) # 入力注をとる\n",
    "            return s\n",
    "        \n",
    "        return [remove(line) for line in lines]\n",
    "        \n",
    "class Tokenize(Process):\n",
    "    \n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def apply(self, lines):\n",
    "        \n",
    "        def filter_by_pos(token, allow_poses):\n",
    "            return token.part_of_speech.split(',')[0] in allow_poses\n",
    "        \n",
    "        def token_to_surface(token):\n",
    "            return token.surface if token.base_form == '*' else token.base_form\n",
    "        \n",
    "        ALLOWED_POS = ['名詞','形容詞','動詞','記号']\n",
    "        return [' '.join([token_to_surface(token) for token in self.tokenizer.tokenize(line) if filter_by_pos(token, ALLOWED_POS)]) for line in lines]\n",
    "        \n",
    "class GenshiModel(Process):\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def apply(self, lines):\n",
    "        \n",
    "        # 分かち書きしたテキストを保存\n",
    "        tokenized_file = self.filename + '.tokenized'\n",
    "        with open(tokenized_file, 'w',encoding='utf-8') as fp:\n",
    "            fp.write(\"\\n\".join(lines))\n",
    "        \n",
    "        #モデルを生成\n",
    "        model_file = self.filename + '.model'\n",
    "        data = word2vec.LineSentence(tokenized_file)\n",
    "        model = word2vec.Word2Vec(data,size=200, window=10, hs = 1, min_count =2, sg = 1)\n",
    "        model.save(model_file)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = DataSet.get('At the Mountains of Madness')\n",
    "\n",
    "t = Task()\n",
    "t.process(DownloadAozora(text))\n",
    "t.process(RemoveMetaData())\n",
    "t.process(Tokenize(Tokenizer()))\n",
    "t.process(GenshiModel(text.filename()))\n",
    "model = t.run(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('アナロジー', 0.9499032497406006),\n",
       " ('神', 0.9487597346305847),\n",
       " ('禁断', 0.9486730694770813),\n",
       " ('永遠', 0.9450716972351074),\n",
       " ('闇', 0.9423696398735046),\n",
       " ('適う', 0.9399266839027405),\n",
       " ('逃げる', 0.9393948316574097),\n",
       " ('道理', 0.9382576942443848),\n",
       " ('叫び', 0.9366800785064697),\n",
       " ('追い立てる', 0.9357254505157471)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['古', '邪悪'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('恐怖', 0.33436575531959534),\n",
       " ('世界', 0.3195968568325043),\n",
       " ('くれる', 0.3060491383075714),\n",
       " ('最後', 0.2898232340812683),\n",
       " ('前', 0.2875790297985077),\n",
       " ('自分', 0.26906710863113403),\n",
       " ('音', 0.2648683488368988),\n",
       " ('外部', 0.25517863035202026),\n",
       " ('自身', 0.2540249228477478),\n",
       " ('しまう', 0.2498125433921814)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['死'], negative=['温度'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
