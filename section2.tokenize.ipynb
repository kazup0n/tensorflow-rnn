{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我々(401)\n",
      "的(324)\n",
      ".(251)\n",
      "一(202)\n",
      "私(161)\n",
      "中(154)\n",
      "二(141)\n",
      "/(137)\n",
      "五(127)\n",
      "-(126)\n",
      "_(124)\n",
      "十(119)\n",
      "彫刻(118)\n",
      "レイク(113)\n",
      "者(112)\n",
      "上(112)\n",
      "何(106)\n",
      "都市(96)\n",
      "三(93)\n",
      "時(92)\n",
      "太字(92)\n",
      "後(86)\n",
      "〇(84)\n",
      "恐怖(84)\n",
      "(*(83)\n",
      "メートル(81)\n",
      "他(79)\n",
      "年(77)\n",
      "氷(75)\n",
      "調査(74)\n",
      "＃「(73)\n",
      "性(72)\n",
      "部(71)\n",
      "彼ら(71)\n",
      "前(70)\n",
      "形(70)\n",
      "一つ(70)\n",
      "間(69)\n",
      "山脈(68)\n",
      "キャンプ(66)\n",
      "部分(66)\n",
      "ダンフォース(66)\n",
      "＃(66)\n",
      "彼(66)\n",
      "大(64)\n",
      "目(63)\n",
      "奇妙(62)\n",
      "四(61)\n",
      "物(61)\n",
      "機(60)\n"
     ]
    }
   ],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tempfile\n",
    "import os\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "class Task:\n",
    "    processes = []\n",
    "    def process(self, process):\n",
    "        self.processes.append(process)\n",
    "        return self\n",
    "    \n",
    "    def run(self, init):\n",
    "        for p in self.processes:\n",
    "            init = p.apply(init)\n",
    "        return init\n",
    "\n",
    "\n",
    "class Process(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def apply(self, init):\n",
    "        pass\n",
    "\n",
    "class DownloadAozora(Process):\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "    \n",
    "    def apply(self, init):\n",
    "        localfile = self.url.split('/')[-1]\n",
    "        if not os.path.exists(localfile):\n",
    "            #download\n",
    "            print('downloading')\n",
    "            urllib.request.urlretrieve(url, localfile)\n",
    "        #unzip\n",
    "        with zipfile.ZipFile(localfile, 'r') as zip_fp:\n",
    "            for entry in zip_fp.infolist():\n",
    "                if entry.filename.find('.txt') > 0:\n",
    "                    with zip_fp.open(entry.filename, 'r') as fp:\n",
    "                        return fp.read().decode('shift_jis')\n",
    "        raise Exception('No text file found in {0}'.format(self.url))\n",
    "\n",
    "\n",
    "class TokenCounter(Process):\n",
    "    \n",
    "    def __init__(self, tokenizer, filter):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.filter = filter\n",
    "    \n",
    "    def apply(self, lines):\n",
    "        counts = {}\n",
    "        for line in lines.split('\\r\\n'):\n",
    "            for token in self.tokenizer.tokenize(line):\n",
    "                if self.filter(token):\n",
    "                    counts[token.surface] = counts.get(token.surface, 0) + 1\n",
    "        return counts\n",
    "\n",
    "def noun_filter(token):\n",
    "\n",
    "    def is_h(title):\n",
    "        a =   [ch for ch in title if \"あ\" <= ch <= \"ん\"]\n",
    "        if len(title) == len(a):\n",
    "            return True\n",
    "        return False\n",
    "    return token.part_of_speech.find('名詞') >= 0 and not is_h(token.surface)\n",
    "\n",
    "class SortByFreq(Process):\n",
    "    \n",
    "    def __init__(self, limit, desc=True):\n",
    "        self.limit = limit\n",
    "        self.desc = desc\n",
    "    \n",
    "    def apply(self, worddic):\n",
    "        keys = sorted(worddic.items(),key = lambda x:x[1], reverse=self.desc)\n",
    "        return [(word, cnt) for word,cnt in keys[:self.limit]]\n",
    "\n",
    "    \n",
    "TEXT = 'http://www.aozora.gr.jp/cards/001699/files/57858_ruby_59671.zip'\n",
    "\n",
    "t = Task()\n",
    "t.process(DownloadAozora(TEXT))\n",
    "t.process(TokenCounter(Tokenizer(), noun_filter))\n",
    "t.process(SortByFreq(50))\n",
    "tokens = t.run(None)\n",
    "\n",
    "for t in tokens:\n",
    "    word, cnt = t[0], t[1]\n",
    "    print(\"{0}({1})\\n\".format(word,cnt), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update expected at most 1 arguments, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-4e0e2e1e6aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: update expected at most 1 arguments, got 2"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
